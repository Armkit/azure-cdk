// generated by armkit
import { ArmResource } from '@armkit/core';
import { Construct } from 'constructs';

/**
 * Microsoft.BatchAI/workspaces
 *
 * @schema Microsoft.BatchAI.workspaces
 */
export class Workspaces extends ArmResource {
  /**
   * Defines a "Microsoft.BatchAI.workspaces" Arm Template object
   * @param scope the scope in which to define this object
   * @param name a scope-local name for the object
   * @param options configuration options
   */
  public constructor(scope: Construct, name: string, options: WorkspacesOptions) {
    super(scope, name, {
      ...options,
      armResourceType: 'workspaces',
    });
  }
}

/**
 * Microsoft.BatchAI/workspaces/clusters
 *
 * @schema Microsoft.BatchAI.workspaces_clusters
 */
export class WorkspacesClusters extends ArmResource {
  /**
   * Defines a "Microsoft.BatchAI.workspaces_clusters" Arm Template object
   * @param scope the scope in which to define this object
   * @param name a scope-local name for the object
   * @param options configuration options
   */
  public constructor(scope: Construct, name: string, options: WorkspacesClustersOptions) {
    super(scope, name, {
      ...options,
      armResourceType: 'workspaces_clusters',
    });
  }
}

/**
 * Microsoft.BatchAI/workspaces/experiments
 *
 * @schema Microsoft.BatchAI.workspaces_experiments
 */
export class WorkspacesExperiments extends ArmResource {
  /**
   * Defines a "Microsoft.BatchAI.workspaces_experiments" Arm Template object
   * @param scope the scope in which to define this object
   * @param name a scope-local name for the object
   * @param options configuration options
   */
  public constructor(scope: Construct, name: string, options: WorkspacesExperimentsOptions) {
    super(scope, name, {
      ...options,
      armResourceType: 'workspaces_experiments',
    });
  }
}

/**
 * Microsoft.BatchAI/workspaces/experiments/jobs
 *
 * @schema Microsoft.BatchAI.workspaces_experiments_jobs
 */
export class WorkspacesExperimentsJobs extends ArmResource {
  /**
   * Defines a "Microsoft.BatchAI.workspaces_experiments_jobs" Arm Template object
   * @param scope the scope in which to define this object
   * @param name a scope-local name for the object
   * @param options configuration options
   */
  public constructor(scope: Construct, name: string, options: WorkspacesExperimentsJobsOptions) {
    super(scope, name, {
      ...options,
      armResourceType: 'workspaces_experiments_jobs',
    });
  }
}

/**
 * Microsoft.BatchAI/workspaces/fileServers
 *
 * @schema Microsoft.BatchAI.workspaces_fileServers
 */
export class WorkspacesFileServers extends ArmResource {
  /**
   * Defines a "Microsoft.BatchAI.workspaces_fileServers" Arm Template object
   * @param scope the scope in which to define this object
   * @param name a scope-local name for the object
   * @param options configuration options
   */
  public constructor(scope: Construct, name: string, options: WorkspacesFileServersOptions) {
    super(scope, name, {
      ...options,
      armResourceType: 'workspaces_fileServers',
    });
  }
}

/**
 * Microsoft.BatchAI/workspaces
 *
 * @schema Microsoft.BatchAI.workspaces
 */
export interface WorkspacesOptions {
  /**
   * @schema Microsoft.BatchAI.workspaces#apiVersion
   */
  readonly apiVersion?: MicrosoftBatchAiWorkspacesApiVersion;

  /**
   * The region in which to create the Workspace.
   *
   * @schema Microsoft.BatchAI.workspaces#location
   */
  readonly location: string;

  /**
   * The name of the workspace. Workspace names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema Microsoft.BatchAI.workspaces#name
   */
  readonly name: MicrosoftBatchAiWorkspacesNamePattern;

  /**
   * @schema Microsoft.BatchAI.workspaces#resources
   */
  readonly resources?: MicrosoftBatchAiWorkspacesResources[];

  /**
   * The user specified tags associated with the Workspace.
   *
   * @schema Microsoft.BatchAI.workspaces#tags
   */
  readonly tags?: MicrosoftBatchAiWorkspacesTags;

  /**
   * @schema Microsoft.BatchAI.workspaces#type
   */
  readonly type: MicrosoftBatchAiWorkspacesType;

}

/**
 * Microsoft.BatchAI/workspaces/clusters
 *
 * @schema Microsoft.BatchAI.workspaces_clusters
 */
export interface WorkspacesClustersOptions {
  /**
   * @schema Microsoft.BatchAI.workspaces_clusters#apiVersion
   */
  readonly apiVersion?: MicrosoftBatchAiWorkspacesClustersApiVersion;

  /**
   * The name of the cluster within the specified resource group. Cluster names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema Microsoft.BatchAI.workspaces_clusters#name
   */
  readonly name: MicrosoftBatchAiWorkspacesClustersNamePattern;

  /**
   * The properties of a Cluster.
   *
   * @schema Microsoft.BatchAI.workspaces_clusters#properties
   */
  readonly properties: ClusterBaseProperties;

  /**
   * @schema Microsoft.BatchAI.workspaces_clusters#type
   */
  readonly type: MicrosoftBatchAiWorkspacesClustersType;

}

/**
 * Microsoft.BatchAI/workspaces/experiments
 *
 * @schema Microsoft.BatchAI.workspaces_experiments
 */
export interface WorkspacesExperimentsOptions {
  /**
   * @schema Microsoft.BatchAI.workspaces_experiments#apiVersion
   */
  readonly apiVersion?: MicrosoftBatchAiWorkspacesExperimentsApiVersion;

  /**
   * The name of the experiment. Experiment names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema Microsoft.BatchAI.workspaces_experiments#name
   */
  readonly name: MicrosoftBatchAiWorkspacesExperimentsNamePattern;

  /**
   * @schema Microsoft.BatchAI.workspaces_experiments#resources
   */
  readonly resources?: WorkspacesExperimentsJobsChildResource[];

  /**
   * @schema Microsoft.BatchAI.workspaces_experiments#type
   */
  readonly type: MicrosoftBatchAiWorkspacesExperimentsType;

}

/**
 * Microsoft.BatchAI/workspaces/experiments/jobs
 *
 * @schema Microsoft.BatchAI.workspaces_experiments_jobs
 */
export interface WorkspacesExperimentsJobsOptions {
  /**
   * @schema Microsoft.BatchAI.workspaces_experiments_jobs#apiVersion
   */
  readonly apiVersion?: MicrosoftBatchAiWorkspacesExperimentsJobsApiVersion;

  /**
   * The name of the job within the specified resource group. Job names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema Microsoft.BatchAI.workspaces_experiments_jobs#name
   */
  readonly name: MicrosoftBatchAiWorkspacesExperimentsJobsNamePattern;

  /**
   * The properties of a Batch AI Job.
   *
   * @schema Microsoft.BatchAI.workspaces_experiments_jobs#properties
   */
  readonly properties: JobBaseProperties;

  /**
   * @schema Microsoft.BatchAI.workspaces_experiments_jobs#type
   */
  readonly type: MicrosoftBatchAiWorkspacesExperimentsJobsType;

}

/**
 * Microsoft.BatchAI/workspaces/fileServers
 *
 * @schema Microsoft.BatchAI.workspaces_fileServers
 */
export interface WorkspacesFileServersOptions {
  /**
   * @schema Microsoft.BatchAI.workspaces_fileServers#apiVersion
   */
  readonly apiVersion?: MicrosoftBatchAiWorkspacesFileServersApiVersion;

  /**
   * The name of the file server within the specified resource group. File server names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema Microsoft.BatchAI.workspaces_fileServers#name
   */
  readonly name: MicrosoftBatchAiWorkspacesFileServersNamePattern;

  /**
   * The properties of a file server.
   *
   * @schema Microsoft.BatchAI.workspaces_fileServers#properties
   */
  readonly properties: FileServerBaseProperties;

  /**
   * @schema Microsoft.BatchAI.workspaces_fileServers#type
   */
  readonly type: MicrosoftBatchAiWorkspacesFileServersType;

}

export enum MicrosoftBatchAiWorkspacesApiVersion {
  "MicrosoftBatchAiWorkspacesApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema MicrosoftBatchAiWorkspacesName
 */
export class MicrosoftBatchAiWorkspacesNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

/**
 * @schema MicrosoftBatchAiWorkspacesResources
 */
export class MicrosoftBatchAiWorkspacesResources {
  public static fromWorkspacesExperimentsChildResource(value: WorkspacesExperimentsChildResource): MicrosoftBatchAiWorkspacesResources {
    return new MicrosoftBatchAiWorkspacesResources(value);
  }
  public static fromWorkspacesFileServersChildResource(value: WorkspacesFileServersChildResource): MicrosoftBatchAiWorkspacesResources {
    return new MicrosoftBatchAiWorkspacesResources(value);
  }
  public static fromWorkspacesClustersChildResource(value: WorkspacesClustersChildResource): MicrosoftBatchAiWorkspacesResources {
    return new MicrosoftBatchAiWorkspacesResources(value);
  }
  private constructor(value: any) {
    Object.defineProperty(this, 'resolve', { value: () => value });
  }
}

/**
 * @schema MicrosoftBatchAiWorkspacesTags
 */
export interface MicrosoftBatchAiWorkspacesTags {
}

export enum MicrosoftBatchAiWorkspacesType {
  "MicrosoftBatchAiWorkspacesType_MICROSOFT_BATCH_AI_WORKSPACES" = 'Microsoft.BatchAI/workspaces',
}

export enum MicrosoftBatchAiWorkspacesClustersApiVersion {
  "MicrosoftBatchAiWorkspacesClustersApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema MicrosoftBatchAiWorkspacesClustersName
 */
export class MicrosoftBatchAiWorkspacesClustersNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

/**
 * The properties of a Cluster.
 *
 * @schema #/definitions/ClusterBaseProperties
 */
export interface ClusterBaseProperties {
  /**
   * Node setup settings.
   *
   * @schema #/definitions/ClusterBaseProperties#nodeSetup
   */
  readonly nodeSetup?: NodeSetup;

  /**
   * At least one of manual or autoScale settings must be specified. Only one of manual or autoScale settings can be specified. If autoScale settings are specified, the system automatically scales the cluster up and down (within the supplied limits) based on the pending jobs on the cluster.
   *
   * @schema #/definitions/ClusterBaseProperties#scaleSettings
   */
  readonly scaleSettings?: ScaleSettings;

  /**
   * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
   *
   * @schema #/definitions/ClusterBaseProperties#subnet
   */
  readonly subnet?: ResourceId;

  /**
   * Settings for user account that gets created on each on the nodes of a cluster.
   *
   * @schema #/definitions/ClusterBaseProperties#userAccountSettings
   */
  readonly userAccountSettings: UserAccountSettings;

  /**
   * VM configuration.
   *
   * @schema #/definitions/ClusterBaseProperties#virtualMachineConfiguration
   */
  readonly virtualMachineConfiguration?: VirtualMachineConfiguration;

  /**
   * VM priority. Allowed values are: dedicated (default) and lowpriority.
   *
   * @schema #/definitions/ClusterBaseProperties#vmPriority
   */
  readonly vmPriority?: ClusterBasePropertiesVmPriority;

  /**
   * The size of the virtual machines in the cluster. All nodes in a cluster have the same VM size. For information about available VM sizes for clusters using images from the Virtual Machines Marketplace see Sizes for Virtual Machines (Linux). Batch AI service supports all Azure VM sizes except STANDARD_A0 and those with premium storage (STANDARD_GS, STANDARD_DS, and STANDARD_DSV2 series).
   *
   * @schema #/definitions/ClusterBaseProperties#vmSize
   */
  readonly vmSize: string;

}

export enum MicrosoftBatchAiWorkspacesClustersType {
  "MicrosoftBatchAiWorkspacesClustersType_MICROSOFT_BATCH_AI_WORKSPACES_CLUSTERS" = 'Microsoft.BatchAI/workspaces/clusters',
}

export enum MicrosoftBatchAiWorkspacesExperimentsApiVersion {
  "MicrosoftBatchAiWorkspacesExperimentsApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema MicrosoftBatchAiWorkspacesExperimentsName
 */
export class MicrosoftBatchAiWorkspacesExperimentsNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

/**
 * Microsoft.BatchAI/workspaces/experiments/jobs
 *
 * @schema #/definitions/workspaces_experiments_jobs_childResource
 */
export interface WorkspacesExperimentsJobsChildResource {
  /**
   * @schema #/definitions/workspaces_experiments_jobs_childResource#apiVersion
   */
  readonly apiVersion: WorkspacesExperimentsJobsChildResourceApiVersion;

  /**
   * The name of the job within the specified resource group. Job names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema #/definitions/workspaces_experiments_jobs_childResource#name
   */
  readonly name: WorkspacesExperimentsJobsChildResourceNamePattern;

  /**
   * The properties of a Batch AI Job.
   *
   * @schema #/definitions/workspaces_experiments_jobs_childResource#properties
   */
  readonly properties: JobBaseProperties;

  /**
   * @schema #/definitions/workspaces_experiments_jobs_childResource#type
   */
  readonly type: WorkspacesExperimentsJobsChildResourceType;

}

export enum MicrosoftBatchAiWorkspacesExperimentsType {
  "MicrosoftBatchAiWorkspacesExperimentsType_MICROSOFT_BATCH_AI_WORKSPACES_EXPERIMENTS" = 'Microsoft.BatchAI/workspaces/experiments',
}

export enum MicrosoftBatchAiWorkspacesExperimentsJobsApiVersion {
  "MicrosoftBatchAiWorkspacesExperimentsJobsApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema MicrosoftBatchAiWorkspacesExperimentsJobsName
 */
export class MicrosoftBatchAiWorkspacesExperimentsJobsNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

/**
 * The properties of a Batch AI Job.
 *
 * @schema #/definitions/JobBaseProperties
 */
export interface JobBaseProperties {
  /**
   * Caffe2 job settings.
   *
   * @schema #/definitions/JobBaseProperties#caffe2Settings
   */
  readonly caffe2Settings?: Caffe2Settings;

  /**
   * Caffe job settings.
   *
   * @schema #/definitions/JobBaseProperties#caffeSettings
   */
  readonly caffeSettings?: CaffeSettings;

  /**
   * Chainer job settings.
   *
   * @schema #/definitions/JobBaseProperties#chainerSettings
   */
  readonly chainerSettings?: ChainerSettings;

  /**
   * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
   *
   * @schema #/definitions/JobBaseProperties#cluster
   */
  readonly cluster: ResourceId;

  /**
   * CNTK (aka Microsoft Cognitive Toolkit) job settings.
   *
   * @schema #/definitions/JobBaseProperties#cntkSettings
   */
  readonly cntkSettings?: CntKsettings;

  /**
   * Constraints associated with the Job.
   *
   * @schema #/definitions/JobBaseProperties#constraints
   */
  readonly constraints?: JobBasePropertiesConstraints;

  /**
   * Docker container settings.
   *
   * @schema #/definitions/JobBaseProperties#containerSettings
   */
  readonly containerSettings?: ContainerSettings;

  /**
   * Custom MPI job settings.
   *
   * @schema #/definitions/JobBaseProperties#customMpiSettings
   */
  readonly customMpiSettings?: CustomMpiSettings;

  /**
   * Custom tool kit job settings.
   *
   * @schema #/definitions/JobBaseProperties#customToolkitSettings
   */
  readonly customToolkitSettings?: CustomToolkitSettings;

  /**
   * A list of user defined environment variables which will be setup for the job.
   *
   * @schema #/definitions/JobBaseProperties#environmentVariables
   */
  readonly environmentVariables?: EnvironmentVariable[];

  /**
   * Specifies the settings for Horovod job.
   *
   * @schema #/definitions/JobBaseProperties#horovodSettings
   */
  readonly horovodSettings?: HorovodSettings;

  /**
   * A list of input directories for the job.
   *
   * @schema #/definitions/JobBaseProperties#inputDirectories
   */
  readonly inputDirectories?: InputDirectory[];

  /**
   * Job preparation settings.
   *
   * @schema #/definitions/JobBaseProperties#jobPreparation
   */
  readonly jobPreparation?: JobPreparation;

  /**
   * Details of volumes to mount on the cluster.
   *
   * @schema #/definitions/JobBaseProperties#mountVolumes
   */
  readonly mountVolumes?: MountVolumes;

  /**
   * Number of compute nodes to run the job on. The job will be gang scheduled on that many compute nodes.
   *
   * @schema #/definitions/JobBaseProperties#nodeCount
   */
  readonly nodeCount: number;

  /**
   * A list of output directories for the job.
   *
   * @schema #/definitions/JobBaseProperties#outputDirectories
   */
  readonly outputDirectories?: OutputDirectory[];

  /**
   * pyTorch job settings.
   *
   * @schema #/definitions/JobBaseProperties#pyTorchSettings
   */
  readonly pyTorchSettings?: PyTorchSettings;

  /**
   * Scheduling priority associated with the job. Possible values: low, normal, high.
   *
   * @schema #/definitions/JobBaseProperties#schedulingPriority
   */
  readonly schedulingPriority?: JobBasePropertiesSchedulingPriority;

  /**
   * A list of user defined environment variables with secret values which will be setup for the job. Server will never report values of these variables back.
   *
   * @schema #/definitions/JobBaseProperties#secrets
   */
  readonly secrets?: EnvironmentVariableWithSecretValue[];

  /**
   * The path where the Batch AI service will store stdout, stderror and execution log of the job.
   *
   * @schema #/definitions/JobBaseProperties#stdOutErrPathPrefix
   */
  readonly stdOutErrPathPrefix: string;

  /**
   * TensorFlow job settings.
   *
   * @schema #/definitions/JobBaseProperties#tensorFlowSettings
   */
  readonly tensorFlowSettings?: TensorFlowSettings;

}

export enum MicrosoftBatchAiWorkspacesExperimentsJobsType {
  "MicrosoftBatchAiWorkspacesExperimentsJobsType_MICROSOFT_BATCH_AI_WORKSPACES_EXPERIMENTS_JOBS" = 'Microsoft.BatchAI/workspaces/experiments/jobs',
}

export enum MicrosoftBatchAiWorkspacesFileServersApiVersion {
  "MicrosoftBatchAiWorkspacesFileServersApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema MicrosoftBatchAiWorkspacesFileServersName
 */
export class MicrosoftBatchAiWorkspacesFileServersNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

/**
 * The properties of a file server.
 *
 * @schema #/definitions/FileServerBaseProperties
 */
export interface FileServerBaseProperties {
  /**
   * Data disks settings.
   *
   * @schema #/definitions/FileServerBaseProperties#dataDisks
   */
  readonly dataDisks: DataDisks;

  /**
   * SSH configuration.
   *
   * @schema #/definitions/FileServerBaseProperties#sshConfiguration
   */
  readonly sshConfiguration: SshConfiguration;

  /**
   * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
   *
   * @schema #/definitions/FileServerBaseProperties#subnet
   */
  readonly subnet?: ResourceId;

  /**
   * The size of the virtual machine for the File Server. For information about available VM sizes from the Virtual Machines Marketplace, see Sizes for Virtual Machines (Linux).
   *
   * @schema #/definitions/FileServerBaseProperties#vmSize
   */
  readonly vmSize: string;

}

export enum MicrosoftBatchAiWorkspacesFileServersType {
  "MicrosoftBatchAiWorkspacesFileServersType_MICROSOFT_BATCH_AI_WORKSPACES_FILE_SERVERS" = 'Microsoft.BatchAI/workspaces/fileServers',
}

/**
 * Microsoft.BatchAI/workspaces/experiments
 *
 * @schema #/definitions/workspaces_experiments_childResource
 */
export interface WorkspacesExperimentsChildResource {
  /**
   * @schema #/definitions/workspaces_experiments_childResource#apiVersion
   */
  readonly apiVersion: WorkspacesExperimentsChildResourceApiVersion;

  /**
   * The name of the experiment. Experiment names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema #/definitions/workspaces_experiments_childResource#name
   */
  readonly name: WorkspacesExperimentsChildResourceNamePattern;

  /**
   * @schema #/definitions/workspaces_experiments_childResource#type
   */
  readonly type: WorkspacesExperimentsChildResourceType;

}

/**
 * Microsoft.BatchAI/workspaces/fileServers
 *
 * @schema #/definitions/workspaces_fileServers_childResource
 */
export interface WorkspacesFileServersChildResource {
  /**
   * @schema #/definitions/workspaces_fileServers_childResource#apiVersion
   */
  readonly apiVersion: WorkspacesFileServersChildResourceApiVersion;

  /**
   * The name of the file server within the specified resource group. File server names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema #/definitions/workspaces_fileServers_childResource#name
   */
  readonly name: WorkspacesFileServersChildResourceNamePattern;

  /**
   * The properties of a file server.
   *
   * @schema #/definitions/workspaces_fileServers_childResource#properties
   */
  readonly properties: FileServerBaseProperties;

  /**
   * @schema #/definitions/workspaces_fileServers_childResource#type
   */
  readonly type: WorkspacesFileServersChildResourceType;

}

/**
 * Microsoft.BatchAI/workspaces/clusters
 *
 * @schema #/definitions/workspaces_clusters_childResource
 */
export interface WorkspacesClustersChildResource {
  /**
   * @schema #/definitions/workspaces_clusters_childResource#apiVersion
   */
  readonly apiVersion: WorkspacesClustersChildResourceApiVersion;

  /**
   * The name of the cluster within the specified resource group. Cluster names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
   *
   * @schema #/definitions/workspaces_clusters_childResource#name
   */
  readonly name: WorkspacesClustersChildResourceNamePattern;

  /**
   * The properties of a Cluster.
   *
   * @schema #/definitions/workspaces_clusters_childResource#properties
   */
  readonly properties: ClusterBaseProperties;

  /**
   * @schema #/definitions/workspaces_clusters_childResource#type
   */
  readonly type: WorkspacesClustersChildResourceType;

}

/**
 * Node setup settings.
 *
 * @schema #/definitions/NodeSetup
 */
export interface NodeSetup {
  /**
   * Details of volumes to mount on the cluster.
   *
   * @schema #/definitions/NodeSetup#mountVolumes
   */
  readonly mountVolumes?: MountVolumes;

  /**
   * Performance counters reporting settings.
   *
   * @schema #/definitions/NodeSetup#performanceCountersSettings
   */
  readonly performanceCountersSettings?: PerformanceCountersSettings;

  /**
   * Specifies a setup task which can be used to customize the compute nodes of the cluster.
   *
   * @schema #/definitions/NodeSetup#setupTask
   */
  readonly setupTask?: SetupTask;

}

/**
 * At least one of manual or autoScale settings must be specified. Only one of manual or autoScale settings can be specified. If autoScale settings are specified, the system automatically scales the cluster up and down (within the supplied limits) based on the pending jobs on the cluster.
 *
 * @schema #/definitions/ScaleSettings
 */
export interface ScaleSettings {
  /**
   * Auto-scale settings for the cluster. The system automatically scales the cluster up and down (within minimumNodeCount and maximumNodeCount) based on the number of queued and running jobs assigned to the cluster.
   *
   * @schema #/definitions/ScaleSettings#autoScale
   */
  readonly autoScale?: AutoScaleSettings;

  /**
   * Manual scale settings for the cluster.
   *
   * @schema #/definitions/ScaleSettings#manual
   */
  readonly manual?: ManualScaleSettings;

}

/**
 * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
 *
 * @schema #/definitions/ResourceId
 */
export interface ResourceId {
  /**
   * The ID of the resource
   *
   * @schema #/definitions/ResourceId#id
   */
  readonly id: string;

}

/**
 * Settings for user account that gets created on each on the nodes of a cluster.
 *
 * @schema #/definitions/UserAccountSettings
 */
export interface UserAccountSettings {
  /**
   * Name of the administrator user account which can be used to SSH to nodes.
   *
   * @schema #/definitions/UserAccountSettings#adminUserName
   */
  readonly adminUserName: string;

  /**
   * Password of the administrator user account.
   *
   * @schema #/definitions/UserAccountSettings#adminUserPassword
   */
  readonly adminUserPassword?: string;

  /**
   * SSH public key of the administrator user account.
   *
   * @schema #/definitions/UserAccountSettings#adminUserSshPublicKey
   */
  readonly adminUserSshPublicKey?: string;

}

/**
 * VM configuration.
 *
 * @schema #/definitions/VirtualMachineConfiguration
 */
export interface VirtualMachineConfiguration {
  /**
   * The OS image reference.
   *
   * @schema #/definitions/VirtualMachineConfiguration#imageReference
   */
  readonly imageReference?: ImageReference;

}

export enum ClusterBasePropertiesVmPriority {
  DEDICATED = 'dedicated',
  LOWPRIORITY = 'lowpriority',
}

export enum WorkspacesExperimentsJobsChildResourceApiVersion {
  "WorkspacesExperimentsJobsChildResourceApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema #/definitions/workspacesExperimentsJobsChildResourceName
 */
export class WorkspacesExperimentsJobsChildResourceNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

export enum WorkspacesExperimentsJobsChildResourceType {
  JOBS = 'jobs',
}

/**
 * Caffe2 job settings.
 *
 * @schema #/definitions/Caffe2Settings
 */
export interface Caffe2Settings {
  /**
   * Command line arguments that need to be passed to the python script.
   *
   * @schema #/definitions/Caffe2Settings#commandLineArgs
   */
  readonly commandLineArgs?: string;

  /**
   * The path to the Python interpreter.
   *
   * @schema #/definitions/Caffe2Settings#pythonInterpreterPath
   */
  readonly pythonInterpreterPath?: string;

  /**
   * The python script to execute.
   *
   * @schema #/definitions/Caffe2Settings#pythonScriptFilePath
   */
  readonly pythonScriptFilePath: string;

}

/**
 * Caffe job settings.
 *
 * @schema #/definitions/CaffeSettings
 */
export interface CaffeSettings {
  /**
   * Command line arguments that need to be passed to the Caffe job.
   *
   * @schema #/definitions/CaffeSettings#commandLineArgs
   */
  readonly commandLineArgs?: string;

  /**
   * Path of the config file for the job. This property cannot be specified if pythonScriptFilePath is specified.
   *
   * @schema #/definitions/CaffeSettings#configFilePath
   */
  readonly configFilePath?: string;

  /**
   * Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property
   *
   * @schema #/definitions/CaffeSettings#processCount
   */
  readonly processCount?: number;

  /**
   * The path to the Python interpreter. The property can be specified only if the pythonScriptFilePath is specified.
   *
   * @schema #/definitions/CaffeSettings#pythonInterpreterPath
   */
  readonly pythonInterpreterPath?: string;

  /**
   * Python script to execute. This property cannot be specified if configFilePath is specified.
   *
   * @schema #/definitions/CaffeSettings#pythonScriptFilePath
   */
  readonly pythonScriptFilePath?: string;

}

/**
 * Chainer job settings.
 *
 * @schema #/definitions/ChainerSettings
 */
export interface ChainerSettings {
  /**
   * Command line arguments that need to be passed to the python script.
   *
   * @schema #/definitions/ChainerSettings#commandLineArgs
   */
  readonly commandLineArgs?: string;

  /**
   * Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property
   *
   * @schema #/definitions/ChainerSettings#processCount
   */
  readonly processCount?: number;

  /**
   * The path to the Python interpreter.
   *
   * @schema #/definitions/ChainerSettings#pythonInterpreterPath
   */
  readonly pythonInterpreterPath?: string;

  /**
   * The python script to execute.
   *
   * @schema #/definitions/ChainerSettings#pythonScriptFilePath
   */
  readonly pythonScriptFilePath: string;

}

/**
 * CNTK (aka Microsoft Cognitive Toolkit) job settings.
 *
 * @schema #/definitions/CNTKsettings
 */
export interface CntKsettings {
  /**
   * Command line arguments that need to be passed to the python script or cntk executable.
   *
   * @schema #/definitions/CNTKsettings#commandLineArgs
   */
  readonly commandLineArgs?: string;

  /**
   * Specifies the path of the BrainScript config file. This property can be specified only if the languageType is 'BrainScript'.
   *
   * @schema #/definitions/CNTKsettings#configFilePath
   */
  readonly configFilePath?: string;

  /**
   * The language to use for launching CNTK (aka Microsoft Cognitive Toolkit) job. Valid values are 'BrainScript' or 'Python'.
   *
   * @schema #/definitions/CNTKsettings#languageType
   */
  readonly languageType?: string;

  /**
   * Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property
   *
   * @schema #/definitions/CNTKsettings#processCount
   */
  readonly processCount?: number;

  /**
   * The path to the Python interpreter. This property can be specified only if the languageType is 'Python'.
   *
   * @schema #/definitions/CNTKsettings#pythonInterpreterPath
   */
  readonly pythonInterpreterPath?: string;

  /**
   * Python script to execute. This property can be specified only if the languageType is 'Python'.
   *
   * @schema #/definitions/CNTKsettings#pythonScriptFilePath
   */
  readonly pythonScriptFilePath?: string;

}

/**
 * Constraints associated with the Job.
 *
 * @schema #/definitions/JobBasePropertiesConstraints
 */
export interface JobBasePropertiesConstraints {
  /**
   * Max time the job can run. Default value: 1 week.
   *
   * @schema #/definitions/JobBasePropertiesConstraints#maxWallClockTime
   */
  readonly maxWallClockTime?: string;

}

/**
 * Docker container settings.
 *
 * @schema #/definitions/ContainerSettings
 */
export interface ContainerSettings {
  /**
   * Information about docker image for the job.
   *
   * @schema #/definitions/ContainerSettings#imageSourceRegistry
   */
  readonly imageSourceRegistry: ImageSourceRegistry;

  /**
   * Size of /dev/shm. Please refer to docker documentation for supported argument formats.
   *
   * @schema #/definitions/ContainerSettings#shmSize
   */
  readonly shmSize?: string;

}

/**
 * Custom MPI job settings.
 *
 * @schema #/definitions/CustomMpiSettings
 */
export interface CustomMpiSettings {
  /**
   * The command line to be executed by mpi runtime on each compute node.
   *
   * @schema #/definitions/CustomMpiSettings#commandLine
   */
  readonly commandLine: string;

  /**
   * Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property
   *
   * @schema #/definitions/CustomMpiSettings#processCount
   */
  readonly processCount?: number;

}

/**
 * Custom tool kit job settings.
 *
 * @schema #/definitions/CustomToolkitSettings
 */
export interface CustomToolkitSettings {
  /**
   * The command line to execute on the master node.
   *
   * @schema #/definitions/CustomToolkitSettings#commandLine
   */
  readonly commandLine?: string;

}

/**
 * An environment variable definition.
 *
 * @schema #/definitions/EnvironmentVariable
 */
export interface EnvironmentVariable {
  /**
   * The name of the environment variable.
   *
   * @schema #/definitions/EnvironmentVariable#name
   */
  readonly name: string;

  /**
   * The value of the environment variable.
   *
   * @schema #/definitions/EnvironmentVariable#value
   */
  readonly value: string;

}

/**
 * Specifies the settings for Horovod job.
 *
 * @schema #/definitions/HorovodSettings
 */
export interface HorovodSettings {
  /**
   * Command line arguments that need to be passed to the python script.
   *
   * @schema #/definitions/HorovodSettings#commandLineArgs
   */
  readonly commandLineArgs?: string;

  /**
   * Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property
   *
   * @schema #/definitions/HorovodSettings#processCount
   */
  readonly processCount?: number;

  /**
   * The path to the Python interpreter.
   *
   * @schema #/definitions/HorovodSettings#pythonInterpreterPath
   */
  readonly pythonInterpreterPath?: string;

  /**
   * The python script to execute.
   *
   * @schema #/definitions/HorovodSettings#pythonScriptFilePath
   */
  readonly pythonScriptFilePath: string;

}

/**
 * Input directory for the job.
 *
 * @schema #/definitions/InputDirectory
 */
export interface InputDirectory {
  /**
   * The ID for the input directory. The job can use AZ_BATCHAI_INPUT_<id> environment variable to find the directory path, where <id> is the value of id attribute.
   *
   * @schema #/definitions/InputDirectory#id
   */
  readonly id: string;

  /**
   * The path to the input directory.
   *
   * @schema #/definitions/InputDirectory#path
   */
  readonly path: string;

}

/**
 * Job preparation settings.
 *
 * @schema #/definitions/JobPreparation
 */
export interface JobPreparation {
  /**
   * The command line to execute. If containerSettings is specified on the job, this commandLine will be executed in the same container as job. Otherwise it will be executed on the node.
   *
   * @schema #/definitions/JobPreparation#commandLine
   */
  readonly commandLine: string;

}

/**
 * Details of volumes to mount on the cluster.
 *
 * @schema #/definitions/MountVolumes
 */
export interface MountVolumes {
  /**
   * A collection of Azure Blob Containers that are to be mounted to the cluster nodes.
   *
   * @schema #/definitions/MountVolumes#azureBlobFileSystems
   */
  readonly azureBlobFileSystems?: AzureBlobFileSystemReference[];

  /**
   * A collection of Azure File Shares that are to be mounted to the cluster nodes.
   *
   * @schema #/definitions/MountVolumes#azureFileShares
   */
  readonly azureFileShares?: AzureFileShareReference[];

  /**
   * A collection of Batch AI File Servers that are to be mounted to the cluster nodes.
   *
   * @schema #/definitions/MountVolumes#fileServers
   */
  readonly fileServers?: FileServerReference[];

  /**
   * A collection of unmanaged file systems that are to be mounted to the cluster nodes.
   *
   * @schema #/definitions/MountVolumes#unmanagedFileSystems
   */
  readonly unmanagedFileSystems?: UnmanagedFileSystemReference[];

}

/**
 * Output directory for the job.
 *
 * @schema #/definitions/OutputDirectory
 */
export interface OutputDirectory {
  /**
   * The ID of the output directory. The job can use AZ_BATCHAI_OUTPUT_<id> environment variable to find the directory path, where <id> is the value of id attribute.
   *
   * @schema #/definitions/OutputDirectory#id
   */
  readonly id: string;

  /**
   * The prefix path where the output directory will be created. Note, this is an absolute path to prefix. E.g. $AZ_BATCHAI_MOUNT_ROOT/MyNFS/MyLogs. The full path to the output directory by combining pathPrefix, jobOutputDirectoryPathSegment (reported by get job) and pathSuffix.
   *
   * @schema #/definitions/OutputDirectory#pathPrefix
   */
  readonly pathPrefix: string;

  /**
   * The suffix path where the output directory will be created. E.g. models. You can find the full path to the output directory by combining pathPrefix, jobOutputDirectoryPathSegment (reported by get job) and pathSuffix.
   *
   * @schema #/definitions/OutputDirectory#pathSuffix
   */
  readonly pathSuffix?: string;

}

/**
 * pyTorch job settings.
 *
 * @schema #/definitions/PyTorchSettings
 */
export interface PyTorchSettings {
  /**
   * Command line arguments that need to be passed to the python script.
   *
   * @schema #/definitions/PyTorchSettings#commandLineArgs
   */
  readonly commandLineArgs?: string;

  /**
   * Type of the communication backend for distributed jobs. Valid values are 'TCP', 'Gloo' or 'MPI'. Not required for non-distributed jobs.
   *
   * @schema #/definitions/PyTorchSettings#communicationBackend
   */
  readonly communicationBackend?: string;

  /**
   * Number of processes to launch for the job execution. The default value for this property is equal to nodeCount property
   *
   * @schema #/definitions/PyTorchSettings#processCount
   */
  readonly processCount?: number;

  /**
   * The path to the Python interpreter.
   *
   * @schema #/definitions/PyTorchSettings#pythonInterpreterPath
   */
  readonly pythonInterpreterPath?: string;

  /**
   * The python script to execute.
   *
   * @schema #/definitions/PyTorchSettings#pythonScriptFilePath
   */
  readonly pythonScriptFilePath: string;

}

export enum JobBasePropertiesSchedulingPriority {
  LOW = 'low',
  NORMAL = 'normal',
  HIGH = 'high',
}

/**
 * An environment variable with secret value definition.
 *
 * @schema #/definitions/EnvironmentVariableWithSecretValue
 */
export interface EnvironmentVariableWithSecretValue {
  /**
   * The name of the environment variable to store the secret value.
   *
   * @schema #/definitions/EnvironmentVariableWithSecretValue#name
   */
  readonly name: string;

  /**
   * The value of the environment variable. This value will never be reported back by Batch AI.
   *
   * @schema #/definitions/EnvironmentVariableWithSecretValue#value
   */
  readonly value?: string;

  /**
   * Key Vault Secret reference.
   *
   * @schema #/definitions/EnvironmentVariableWithSecretValue#valueSecretReference
   */
  readonly valueSecretReference?: KeyVaultSecretReference;

}

/**
 * TensorFlow job settings.
 *
 * @schema #/definitions/TensorFlowSettings
 */
export interface TensorFlowSettings {
  /**
   * Command line arguments that need to be passed to the python script for the master task.
   *
   * @schema #/definitions/TensorFlowSettings#masterCommandLineArgs
   */
  readonly masterCommandLineArgs?: string;

  /**
   * Command line arguments that need to be passed to the python script for the parameter server. Optional for single process jobs.
   *
   * @schema #/definitions/TensorFlowSettings#parameterServerCommandLineArgs
   */
  readonly parameterServerCommandLineArgs?: string;

  /**
   * The number of parameter server tasks. If specified, the value must be less than or equal to nodeCount. If not specified, the default value is equal to 1 for distributed TensorFlow training. This property can be specified only for distributed TensorFlow training.
   *
   * @schema #/definitions/TensorFlowSettings#parameterServerCount
   */
  readonly parameterServerCount?: number;

  /**
   * The path to the Python interpreter.
   *
   * @schema #/definitions/TensorFlowSettings#pythonInterpreterPath
   */
  readonly pythonInterpreterPath?: string;

  /**
   * The python script to execute.
   *
   * @schema #/definitions/TensorFlowSettings#pythonScriptFilePath
   */
  readonly pythonScriptFilePath: string;

  /**
   * Command line arguments that need to be passed to the python script for the worker task. Optional for single process jobs.
   *
   * @schema #/definitions/TensorFlowSettings#workerCommandLineArgs
   */
  readonly workerCommandLineArgs?: string;

  /**
   * The number of worker tasks. If specified, the value must be less than or equal to (nodeCount * numberOfGPUs per VM). If not specified, the default value is equal to nodeCount. This property can be specified only for distributed TensorFlow training.
   *
   * @schema #/definitions/TensorFlowSettings#workerCount
   */
  readonly workerCount?: number;

}

/**
 * Data disks settings.
 *
 * @schema #/definitions/DataDisks
 */
export interface DataDisks {
  /**
   * Caching type for the disks. Available values are none (default), readonly, readwrite. Caching type can be set only for VM sizes supporting premium storage.
   *
   * @schema #/definitions/DataDisks#cachingType
   */
  readonly cachingType?: DataDisksCachingType;

  /**
   * Number of data disks attached to the File Server. If multiple disks attached, they will be configured in RAID level 0.
   *
   * @schema #/definitions/DataDisks#diskCount
   */
  readonly diskCount: number;

  /**
   * Disk size in GB for the blank data disks.
   *
   * @schema #/definitions/DataDisks#diskSizeInGB
   */
  readonly diskSizeInGB: number;

  /**
   * Type of storage account to be used on the disk. Possible values are: Standard_LRS or Premium_LRS. Premium storage account type can only be used with VM sizes supporting premium storage.
   *
   * @schema #/definitions/DataDisks#storageAccountType
   */
  readonly storageAccountType: DataDisksStorageAccountType;

}

/**
 * SSH configuration.
 *
 * @schema #/definitions/SshConfiguration
 */
export interface SshConfiguration {
  /**
   * List of source IP ranges to allow SSH connection from. The default value is '*' (all source IPs are allowed). Maximum number of IP ranges that can be specified is 400.
   *
   * @schema #/definitions/SshConfiguration#publicIPsToAllow
   */
  readonly publicIPsToAllow?: string[];

  /**
   * Settings for user account that gets created on each on the nodes of a cluster.
   *
   * @schema #/definitions/SshConfiguration#userAccountSettings
   */
  readonly userAccountSettings: UserAccountSettings;

}

export enum WorkspacesExperimentsChildResourceApiVersion {
  "WorkspacesExperimentsChildResourceApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema #/definitions/workspacesExperimentsChildResourceName
 */
export class WorkspacesExperimentsChildResourceNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

export enum WorkspacesExperimentsChildResourceType {
  EXPERIMENTS = 'experiments',
}

export enum WorkspacesFileServersChildResourceApiVersion {
  "WorkspacesFileServersChildResourceApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema #/definitions/workspacesFileServersChildResourceName
 */
export class WorkspacesFileServersChildResourceNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

export enum WorkspacesFileServersChildResourceType {
  FILE_SERVERS = 'fileServers',
}

export enum WorkspacesClustersChildResourceApiVersion {
  "WorkspacesClustersChildResourceApiVersion_2018_05_01" = '2018-05-01',
}

/**
 * @schema #/definitions/workspacesClustersChildResourceName
 */
export class WorkspacesClustersChildResourceNamePattern {
  public static pattern(value: string): string {
    return value;
  }
}

export enum WorkspacesClustersChildResourceType {
  CLUSTERS = 'clusters',
}

/**
 * Performance counters reporting settings.
 *
 * @schema #/definitions/PerformanceCountersSettings
 */
export interface PerformanceCountersSettings {
  /**
   * Azure Application Insights information for performance counters reporting.
   *
   * @schema #/definitions/PerformanceCountersSettings#appInsightsReference
   */
  readonly appInsightsReference: AppInsightsReference;

}

/**
 * Specifies a setup task which can be used to customize the compute nodes of the cluster.
 *
 * @schema #/definitions/SetupTask
 */
export interface SetupTask {
  /**
   * The command line to be executed on each cluster's node after it being allocated or rebooted. The command is executed in a bash subshell as a root.
   *
   * @schema #/definitions/SetupTask#commandLine
   */
  readonly commandLine: string;

  /**
   * A collection of user defined environment variables to be set for setup task.
   *
   * @schema #/definitions/SetupTask#environmentVariables
   */
  readonly environmentVariables?: EnvironmentVariable[];

  /**
   * A collection of user defined environment variables with secret values to be set for the setup task. Server will never report values of these variables back.
   *
   * @schema #/definitions/SetupTask#secrets
   */
  readonly secrets?: EnvironmentVariableWithSecretValue[];

  /**
   * The prefix of a path where the Batch AI service will upload the stdout, stderr and execution log of the setup task.
   *
   * @schema #/definitions/SetupTask#stdOutErrPathPrefix
   */
  readonly stdOutErrPathPrefix: string;

}

/**
 * Auto-scale settings for the cluster. The system automatically scales the cluster up and down (within minimumNodeCount and maximumNodeCount) based on the number of queued and running jobs assigned to the cluster.
 *
 * @schema #/definitions/AutoScaleSettings
 */
export interface AutoScaleSettings {
  /**
   * The number of compute nodes to allocate on cluster creation. Note that this value is used only during cluster creation. Default: 0.
   *
   * @schema #/definitions/AutoScaleSettings#initialNodeCount
   */
  readonly initialNodeCount?: number;

  /**
   * The maximum number of compute nodes the cluster can have.
   *
   * @schema #/definitions/AutoScaleSettings#maximumNodeCount
   */
  readonly maximumNodeCount: number;

  /**
   * The minimum number of compute nodes the Batch AI service will try to allocate for the cluster. Note, the actual number of nodes can be less than the specified value if the subscription has not enough quota to fulfill the request.
   *
   * @schema #/definitions/AutoScaleSettings#minimumNodeCount
   */
  readonly minimumNodeCount: number;

}

/**
 * Manual scale settings for the cluster.
 *
 * @schema #/definitions/ManualScaleSettings
 */
export interface ManualScaleSettings {
  /**
   * An action to be performed when the cluster size is decreasing. The default value is requeue.
   *
   * @schema #/definitions/ManualScaleSettings#nodeDeallocationOption
   */
  readonly nodeDeallocationOption?: ManualScaleSettingsNodeDeallocationOption;

  /**
   * The desired number of compute nodes in the Cluster. Default is 0.
   *
   * @default 0.
   * @schema #/definitions/ManualScaleSettings#targetNodeCount
   */
  readonly targetNodeCount: number;

}

/**
 * The OS image reference.
 *
 * @schema #/definitions/ImageReference
 */
export interface ImageReference {
  /**
   * Offer of the image.
   *
   * @schema #/definitions/ImageReference#offer
   */
  readonly offer: string;

  /**
   * Publisher of the image.
   *
   * @schema #/definitions/ImageReference#publisher
   */
  readonly publisher: string;

  /**
   * SKU of the image.
   *
   * @schema #/definitions/ImageReference#sku
   */
  readonly sku: string;

  /**
   * Version of the image.
   *
   * @schema #/definitions/ImageReference#version
   */
  readonly version?: string;

  /**
   * The ARM resource identifier of the virtual machine image for the compute nodes. This is of the form /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/images/{imageName}. The virtual machine image must be in the same region and subscription as the cluster. For information about the firewall settings for the Batch node agent to communicate with the Batch service see https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration. Note, you need to provide publisher, offer and sku of the base OS image of which the custom image has been derived from.
   *
   * @schema #/definitions/ImageReference#virtualMachineImageId
   */
  readonly virtualMachineImageId?: string;

}

/**
 * Information about docker image for the job.
 *
 * @schema #/definitions/ImageSourceRegistry
 */
export interface ImageSourceRegistry {
  /**
   * Credentials to access a container image in a private repository.
   *
   * @schema #/definitions/ImageSourceRegistry#credentials
   */
  readonly credentials?: PrivateRegistryCredentials;

  /**
   * The name of the image in the image repository.
   *
   * @schema #/definitions/ImageSourceRegistry#image
   */
  readonly image: string;

  /**
   * URL for image repository.
   *
   * @schema #/definitions/ImageSourceRegistry#serverUrl
   */
  readonly serverUrl?: string;

}

/**
 * Azure Blob Storage Container mounting configuration.
 *
 * @schema #/definitions/AzureBlobFileSystemReference
 */
export interface AzureBlobFileSystemReference {
  /**
   * Name of the Azure storage account.
   *
   * @schema #/definitions/AzureBlobFileSystemReference#accountName
   */
  readonly accountName: string;

  /**
   * Name of the Azure Blob Storage container to mount on the cluster.
   *
   * @schema #/definitions/AzureBlobFileSystemReference#containerName
   */
  readonly containerName: string;

  /**
   * Azure storage account credentials.
   *
   * @schema #/definitions/AzureBlobFileSystemReference#credentials
   */
  readonly credentials: AzureStorageCredentialsInfo;

  /**
   * Mount options for mounting blobfuse file system.
   *
   * @schema #/definitions/AzureBlobFileSystemReference#mountOptions
   */
  readonly mountOptions?: string;

  /**
   * The relative path on the compute node where the Azure File container will be mounted. Note that all cluster level containers will be mounted under $AZ_BATCHAI_MOUNT_ROOT location and all job level containers will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT.
   *
   * @schema #/definitions/AzureBlobFileSystemReference#relativeMountPath
   */
  readonly relativeMountPath: string;

}

/**
 * Azure File Share mounting configuration.
 *
 * @schema #/definitions/AzureFileShareReference
 */
export interface AzureFileShareReference {
  /**
   * Name of the Azure storage account.
   *
   * @schema #/definitions/AzureFileShareReference#accountName
   */
  readonly accountName: string;

  /**
   * URL to access the Azure File.
   *
   * @schema #/definitions/AzureFileShareReference#azureFileUrl
   */
  readonly azureFileUrl: string;

  /**
   * Azure storage account credentials.
   *
   * @schema #/definitions/AzureFileShareReference#credentials
   */
  readonly credentials: AzureStorageCredentialsInfo;

  /**
   * File mode for directories on the mounted file share. Default value: 0777.
   *
   * @schema #/definitions/AzureFileShareReference#directoryMode
   */
  readonly directoryMode?: string;

  /**
   * File mode for files on the mounted file share. Default value: 0777.
   *
   * @schema #/definitions/AzureFileShareReference#fileMode
   */
  readonly fileMode?: string;

  /**
   * The relative path on the compute node where the Azure File share will be mounted. Note that all cluster level file shares will be mounted under $AZ_BATCHAI_MOUNT_ROOT location and all job level file shares will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT.
   *
   * @schema #/definitions/AzureFileShareReference#relativeMountPath
   */
  readonly relativeMountPath: string;

}

/**
 * File Server mounting configuration.
 *
 * @schema #/definitions/FileServerReference
 */
export interface FileServerReference {
  /**
   * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
   *
   * @schema #/definitions/FileServerReference#fileServer
   */
  readonly fileServer: ResourceId;

  /**
   * Mount options to be passed to mount command.
   *
   * @schema #/definitions/FileServerReference#mountOptions
   */
  readonly mountOptions?: string;

  /**
   * The relative path on the compute node where the File Server will be mounted. Note that all cluster level file servers will be mounted under $AZ_BATCHAI_MOUNT_ROOT location and all job level file servers will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT.
   *
   * @schema #/definitions/FileServerReference#relativeMountPath
   */
  readonly relativeMountPath: string;

  /**
   * File Server directory that needs to be mounted. If this property is not specified, the entire File Server will be mounted.
   *
   * @schema #/definitions/FileServerReference#sourceDirectory
   */
  readonly sourceDirectory?: string;

}

/**
 * Unmanaged file system mounting configuration.
 *
 * @schema #/definitions/UnmanagedFileSystemReference
 */
export interface UnmanagedFileSystemReference {
  /**
   * Mount command line. Note, Batch AI will append mount path to the command on its own.
   *
   * @schema #/definitions/UnmanagedFileSystemReference#mountCommand
   */
  readonly mountCommand: string;

  /**
   * The relative path on the compute node where the unmanaged file system will be mounted. Note that all cluster level unmanaged file systems will be mounted under $AZ_BATCHAI_MOUNT_ROOT location and all job level unmanaged file systems will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT.
   *
   * @schema #/definitions/UnmanagedFileSystemReference#relativeMountPath
   */
  readonly relativeMountPath: string;

}

/**
 * Key Vault Secret reference.
 *
 * @schema #/definitions/KeyVaultSecretReference
 */
export interface KeyVaultSecretReference {
  /**
   * The URL referencing a secret in the Key Vault.
   *
   * @schema #/definitions/KeyVaultSecretReference#secretUrl
   */
  readonly secretUrl: string;

  /**
   * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
   *
   * @schema #/definitions/KeyVaultSecretReference#sourceVault
   */
  readonly sourceVault: ResourceId;

}

export enum DataDisksCachingType {
  NONE = 'none',
  READONLY = 'readonly',
  READWRITE = 'readwrite',
}

export enum DataDisksStorageAccountType {
  STANDARD_LRS = 'Standard_LRS',
  PREMIUM_LRS = 'Premium_LRS',
}

/**
 * Azure Application Insights information for performance counters reporting.
 *
 * @schema #/definitions/AppInsightsReference
 */
export interface AppInsightsReference {
  /**
   * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
   *
   * @schema #/definitions/AppInsightsReference#component
   */
  readonly component: ResourceId;

  /**
   * Value of the Azure Application Insights instrumentation key.
   *
   * @schema #/definitions/AppInsightsReference#instrumentationKey
   */
  readonly instrumentationKey?: string;

  /**
   * Key Vault Secret reference.
   *
   * @schema #/definitions/AppInsightsReference#instrumentationKeySecretReference
   */
  readonly instrumentationKeySecretReference?: KeyVaultSecretReference;

}

export enum ManualScaleSettingsNodeDeallocationOption {
  REQUEUE = 'requeue',
  TERMINATE = 'terminate',
  WAITFORJOBCOMPLETION = 'waitforjobcompletion',
}

/**
 * Credentials to access a container image in a private repository.
 *
 * @schema #/definitions/PrivateRegistryCredentials
 */
export interface PrivateRegistryCredentials {
  /**
   * User password to login to the docker repository. One of password or passwordSecretReference must be specified.
   *
   * @schema #/definitions/PrivateRegistryCredentials#password
   */
  readonly password?: string;

  /**
   * Key Vault Secret reference.
   *
   * @schema #/definitions/PrivateRegistryCredentials#passwordSecretReference
   */
  readonly passwordSecretReference?: KeyVaultSecretReference;

  /**
   * User name to login to the repository.
   *
   * @schema #/definitions/PrivateRegistryCredentials#username
   */
  readonly username: string;

}

/**
 * Azure storage account credentials.
 *
 * @schema #/definitions/AzureStorageCredentialsInfo
 */
export interface AzureStorageCredentialsInfo {
  /**
   * Storage account key. One of accountKey or accountKeySecretReference must be specified.
   *
   * @schema #/definitions/AzureStorageCredentialsInfo#accountKey
   */
  readonly accountKey?: string;

  /**
   * Key Vault Secret reference.
   *
   * @schema #/definitions/AzureStorageCredentialsInfo#accountKeySecretReference
   */
  readonly accountKeySecretReference?: KeyVaultSecretReference;

}

